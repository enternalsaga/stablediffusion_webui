{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enternalsaga/stablediffusion_webui/blob/master/NBA_kohya_ss_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og0GQn5TuJNc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown | Gb Vram (Spec) | Resolution | Batch Size |\n",
        "# @markdown | :---: | :---: | :---: |\n",
        "# @markdown | 6-8 | 512 | 1 |\n",
        "# @markdown | 10 | 512 | 2 |\n",
        "# @markdown | 12 | 512 | 3 |\n",
        "# @markdown | 16 (T4) - fp16 | 512 | 5 |\n",
        "# @markdown |  | 768 | 3 |\n",
        "# @markdown | 24 | 512 | 10 |\n",
        "# @markdown |  | 768 | 5 |\n",
        "# @markdown | 32 (V100) -fp16 | 512 | 13 |\n",
        "# @markdown |  | 768 | 9 |\n",
        "# @markdown |  | 1024 | 5 |\n",
        "# @markdown | 40 (A100) - bf16| 512 | 15 |\n",
        "# @markdown |  | 768 | 11 |\n",
        "# @markdown |  | 1024 | 6 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0A8XeuNVLif",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define parameters\n",
        "CheckpointDownloadLink = \"\" #@param {type:\"string\"}\n",
        "Phong_cách_muốn_tạo = \"Realistic_Sharp\"  # @param [\"drawing_painting\", \"Anime_3D\", \"Anime\", \"Realistic_Sharp\", \"Realistic\", \"photon\", \"MidJourneyV4_Style\", \"Default\"]\n",
        "reg_folder = \"\"  # @param [\"\", \"person\", \"woman\", \"interior\", \"exterior_townhouse\"] {allow-input: false}\n",
        "\n",
        "# Define a dictionary of model links\n",
        "models = {\n",
        "    \"Animefull-final-pruned\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "    \"Anything-v3-1\": \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "    \"drawing_painting\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
        "    \"photon\": \"https://huggingface.co/digiplay/Photon_v1/resolve/main/photon_v1.safetensors\",\n",
        "    \"Anime_3D\": \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AAM_Anylora_AnimeMix.safetensors\",\n",
        "    \"Anime\": \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "    \"Realistic_Sharp\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "    \"Realistic\": \"https://huggingface.co/SG161222/Realistic_Vision_V5.0_noVAE/resolve/main/Realistic_Vision_V5.0.safetensors\",\n",
        "    \"MidJourneyV4_Style\": \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "    \"Default\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
        "}\n",
        "\n",
        "# Define a dictionary of regularization links\n",
        "regs = {\n",
        "    \"none\": \"\",\n",
        "    \"person\": \"https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/resolve/main/person_v1-5_mse_vae_ddim50_cfg7_n2115.zip\",\n",
        "    \"woman\": \"https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/resolve/main/woman_v1-5_mse_vae_ddim50_cfg7_n4420.zip\",\n",
        "    \"interior\": \"https://huggingface.co/datasets/enternalsaga/SD-1.5_reg_img/resolve/main/regularization-interior.zip\",\n",
        "    \"exterior_townhouse\": \"https://huggingface.co/datasets/enternalsaga/SD-1.5_reg_img/resolve/main/regularization-exterior_house.zip\",\n",
        "}\n",
        "\n",
        "# Define the folder path for download\n",
        "checkpoint_folder = '/content/chkp_folder/'\n",
        "reg_subfolder = os.path.join(\"/content/reg_folder\", reg_folder)\n",
        "# Create the content/reg/ folder if it doesn't exist\n",
        "if not os.path.exists(reg_subfolder):\n",
        "    os.makedirs(reg_subfolder)\n",
        "\n",
        "# Download and unzip the file from the regularization links\n",
        "if reg_folder in regs and regs[reg_folder]:\n",
        "    reg_link = regs[reg_folder]\n",
        "    zip_filename = reg_link.split('/')[-1]  # Extract the filename from the URL\n",
        "    zip_path = os.path.join(\"/content/reg_folder\", zip_filename)  # Path to save the zip file\n",
        "    reg_path = os.path.join(reg_subfolder, \"1_\" + reg_folder)\n",
        "\n",
        "    # Check if the folder is empty before extracting\n",
        "    if not os.listdir(reg_subfolder):\n",
        "        # Download the zip file\n",
        "        !wget \"$reg_link\" -O \"$zip_path\"\n",
        "\n",
        "        # Extract the downloaded file directly into the subfolder\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(reg_subfolder)\n",
        "        # Rename the extracted folder to \"1_\" + Regularisation_folder\n",
        "        extracted_folder = os.path.join(reg_subfolder, os.listdir(reg_subfolder)[0])\n",
        "        new_folder_name = os.path.join(reg_subfolder, \"1_\" + reg_folder)\n",
        "        os.rename(extracted_folder, new_folder_name)\n",
        "        print(f\"Renamed folder to {new_folder_name}\")\n",
        "\n",
        "        # Provide a download link for the user\n",
        "        print(f\"Regularization files downloaded and saved to '{reg_subfolder}'.\")\n",
        "    else:\n",
        "        print(f\"The folder '{reg_subfolder}' is not empty. Skipping extraction.\")\n",
        "else:\n",
        "    print(\"No regularization link provided. Please specify a regularization link.\")\n",
        "\n",
        "# Check if CheckpointDownloadLink is provided, otherwise use Phong_cách_muốn_tạo\n",
        "if not CheckpointDownloadLink and Phong_cách_muốn_tạo in models:\n",
        "    CheckpointDownloadLink = models[Phong_cách_muốn_tạo]\n",
        "\n",
        "# Download the file from the link and save it to the specified folder\n",
        "if CheckpointDownloadLink:\n",
        "    filename = CheckpointDownloadLink.split('/')[-1]  # Extract the filename from the URL\n",
        "    output_path = os.path.join(checkpoint_folder, filename)\n",
        "    !wget \"$CheckpointDownloadLink\" -O \"$filename\"\n",
        "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "    # Move the downloaded file to the content folder\n",
        "    !mv \"$filename\" \"/content/chkp_folder/$filename\"\n",
        "\n",
        "    # Provide a download link for the user\n",
        "    print(f\"File downloaded and saved to {output_path}. You can now use it\")\n",
        "else:\n",
        "    print(\"No download link provided. Please specify a download link.\")\n",
        "\n",
        "#@title <font size=\"5\" color=\"orange\">Step 1: Upload images and print folder names </font>\n",
        "#@markdown Begineers: Use a different `Project_folder` each time when you upload the images.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_name = 'IndustrialWarehouse' #@param {type:\"string\"}\n",
        "Number_of_epoches = 1 #@param {type:\"integer\"}\n",
        "\n",
        "# construct paths\n",
        "projectPath = '/content/drive/MyDrive/SD_Train/TrainFolder/' + dataset_name\n",
        "imagePath = projectPath + '/img/' + str(Number_of_epoches) + '_'+ dataset_name\n",
        "loraPath = projectPath + '/lora/'\n",
        "\n",
        "!mkdir -p {loraPath}\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(imagePath):\n",
        "  print(f'Error: Folder {imagePath} already exists. Please use a different project folder or dataset names. Skip uploading.\\n')\n",
        "else:\n",
        "  !mkdir -p {imagePath}\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "      dst_path = imagePath + '/' + filename\n",
        "      shutil.move(filename, dst_path)\n",
        "  print('Images uploaded successfully.\\n')\n",
        "\n",
        "# print image paths\n",
        "print(f\"Image folder to caption: {imagePath}\")\n",
        "print(f\"Lora Image folder: {projectPath}\")\n",
        "print(f\"Lora output folder: {loraPath}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJNcuWdw_OKy"
      },
      "outputs": [],
      "source": [
        "#@title Train with Kohya's Stable Diffusion Trainers\n",
        "Clear_Log = True\n",
        "\n",
        "def clear():\n",
        "    from IPython.display import clear_output; return clear_output()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!pip install dadaptation==3.1 diffusers[torch]==0.24.0 easygui==0.98.3 einops==0.6.0 fairscale==0.4.13 ftfy==6.1.1 gradio==3.36.1 huggingface-hub==0.19.4\n",
        "!pip install lion-pytorch==0.0.6 lycoris_lora==1.8.0.dev6 open-clip-torch==2.20.0 prodigyopt==1.0 pytorch-lightning==1.9.0 safetensors==0.3.1 timm==0.6.12\n",
        "!pip install tk==0.1.0 transformers==4.30.2 voluptuous==0.13.1 wandb==0.15.0 xformers==0.0.20 omegaconf\n",
        "\n",
        "\n",
        "# Install bitsandbytes\n",
        "!git clone -b 0.41.0 https://github.com/TimDettmers/bitsandbytes\n",
        "%cd /content/bitsandbytes\n",
        "!CUDA_VERSION=117 make cuda11x\n",
        "!python setup.py install\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/bmaltais/kohya_ss.git\n",
        "%cd kohya_ss/\n",
        "!git checkout v21.8.9\n",
        "\n",
        "if Clear_Log:\n",
        "  clear()\n",
        "\n",
        "# add pwd to python path or else blip captioning won't work\n",
        "%env PYTHONPATH=/env/python:/content/kohya_ss\n",
        "!python kohya_gui.py --share --headless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZLW8tVp5407"
      },
      "source": [
        "TL;DR: if you have the right hardware, use BF16 :-)\n",
        "\n",
        "Both consume the exact same memory as they encode each number on 16 bits.\n",
        "\n",
        "On recent Nvidia GPU (Ampere generation like A100 and 3090 RTX), tensor cores boost both of them. On older ones (like a V100 or a T4), bfloat16 is not supported so life is easier because you have no choice. Google TPU supports BF16 since quite some time.The diff between them is in the number of bits for the exponent part and the mantissa."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}